{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'C:/Users/Ubits.PC220318/Documents/GitHub/content_classification\\path/to/your/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath/to/your/data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m train_test_split(dataset, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\load.py:2523\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2518\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2519\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2520\u001b[0m )\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2523\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2524\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2525\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2526\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2527\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2528\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2529\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2530\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2531\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2532\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2533\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2534\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2535\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2536\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2537\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2538\u001b[0m )\n\u001b[0;32m   2540\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\load.py:2195\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   2194\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 2195\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2207\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\load.py:1736\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m \n\u001b[0;32m   1728\u001b[0m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[0;32m   1729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[0;32m   1730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPackagedDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\load.py:1120\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1118\u001b[0m base_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m   1119\u001b[0m patterns \u001b[38;5;241m=\u001b[39m sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns(base_path)\n\u001b[1;32m-> 1120\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1125\u001b[0m supports_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _MODULE_SUPPORTS_METADATA\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m supports_metadata \u001b[38;5;129;01mand\u001b[39;00m patterns \u001b[38;5;241m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\data_files.py:689\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    686\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    688\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 689\u001b[0m         \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m patterns_for_key\n\u001b[0;32m    697\u001b[0m     )\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\data_files.py:594\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    593\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 594\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m         )\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\datasets\\data_files.py:383\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[1;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to find 'C:/Users/Ubits.PC220318/Documents/GitHub/content_classification\\path/to/your/data.csv'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_dataset('csv', data_files='path/to/your/data.csv', split='train')\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from datasets) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python310\\lib\\site-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\python310\\lib\\site-packages (from datasets) (8.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in c:\\python310\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python310\\lib\\site-packages (from datasets) (2.28.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\python310\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.1-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\python310\\lib\\site-packages (from datasets) (0.20.2)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl.metadata (32 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "   ---------------------------------------- 507.1/507.1 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 115.3/115.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "   ---------------------------------------- 166.4/166.4 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.1-cp310-cp310-win_amd64.whl (364 kB)\n",
      "   ---------------------------------------- 364.6/364.6 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 134.8/134.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 50.4/50.4 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 76.4/76.4 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.2\n",
      "    Uninstalling fsspec-2023.12.2:\n",
      "      Successfully uninstalled fsspec-2023.12.2\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.16.1 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from vertexai.preview.language_models import TextEmbeddingModel\n",
    "#model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextEmbeddingModel, TextEmbeddingModelTokenizer\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual\")\n",
    "tokenizer = TextEmbeddingModelTokenizer.from_pretrained('textembedding-gecko-multilingual')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='path/to/output/directory',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    logging_dir='path/to/logging/directory',\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    evaluation_strategy='epoch',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('path/to/fine-tuned/model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
